{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10944218,"sourceType":"datasetVersion","datasetId":6806789}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["\"\"\"\n","Copyright (C) 2022 King Saud University, Saudi Arabia\n","SPDX-License-Identifier: Apache-2.0\n","\n","Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use\n","this file except in compliance with the License. You may obtain a copy of the\n","License at\n","\n","http://www.apache.org/licenses/LICENSE-2.0\n","\n","Unless required by applicable law or agreed to in writing, software distributed\n","under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR\n","CONDITIONS OF ANY KIND, either express or implied. See the License for the\n","specific language governing permissions and limitations under the License.\n","\n","Author:  Hamdi Altaheri\n","\"\"\"\n","\n","import math\n","import numpy as np\n","import pandas as pd\n","import pywt\n","import tensorflow as tf\n","from tensorflow.keras import layers, models, Input, regularizers\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ReduceLROnPlateau\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense\n","from tensorflow.keras.layers import multiply, Permute, Concatenate, Conv2D, Add, Activation, Lambda, Dropout, MultiHeadAttention, LayerNormalization\n","\n","#########################\n","# Advanced Attention Blocks\n","#########################\n","def attention_block(in_layer, attention_model, ratio=8, residual=False, apply_to_input=True):\n","    in_sh = in_layer.shape  # shape of the input tensor\n","    in_len = len(in_sh)\n","    expanded_axis = 2  # default expansion axis for 3D -> 4D conversion\n","\n","    if attention_model == 'mha':   # Multi-head self attention layer\n","        if in_len > 3:\n","            in_layer = Reshape((in_sh[1], -1))(in_layer)\n","        out_layer = mha_block(in_layer)\n","    elif attention_model == 'mhla':  # Multi-head local self-attention layer\n","        if in_len > 3:\n","            in_layer = Reshape((in_sh[1], -1))(in_layer)\n","        out_layer = mha_block(in_layer, vanilla=False)\n","    elif attention_model == 'se':   # Squeeze-and-excitation layer\n","        if in_len < 4:\n","            in_layer = tf.expand_dims(in_layer, axis=expanded_axis)\n","        out_layer = se_block(in_layer, ratio, residual, apply_to_input)\n","    elif attention_model == 'cbam': # Convolutional Block Attention Module\n","        if in_len < 4:\n","            in_layer = tf.expand_dims(in_layer, axis=expanded_axis)\n","        out_layer = cbam_block(in_layer, ratio=ratio, residual=residual)\n","    else:\n","        raise Exception(\"'{}' is not supported attention module!\".format(attention_model))\n","\n","    if in_len == 3 and len(out_layer.shape) == 4:\n","        out_layer = tf.squeeze(out_layer, expanded_axis)\n","    elif in_len == 4 and len(out_layer.shape) == 3:\n","        out_layer = Reshape((in_sh[1], in_sh[2], in_sh[3]))(out_layer)\n","    return out_layer\n","\n","def mha_block(input_feature, key_dim=8, num_heads=2, dropout=0.5, vanilla=True):\n","    \"\"\"Multi-head self Attention block.\"\"\"\n","    x = LayerNormalization(epsilon=1e-6)(input_feature)\n","    if vanilla:\n","        x = MultiHeadAttention(key_dim=key_dim, num_heads=num_heads, dropout=dropout)(x, x)\n","    else:\n","        NUM_PATCHES = input_feature.shape[1]\n","        diag_attn_mask = 1 - tf.eye(NUM_PATCHES)\n","        diag_attn_mask = tf.cast([diag_attn_mask], dtype=tf.int8)\n","        x = MultiHeadAttention_LSA(key_dim=key_dim, num_heads=num_heads, dropout=dropout)(x, x, attention_mask=diag_attn_mask)\n","    x = Dropout(0.3)(x)\n","    mha_feature = Add()([input_feature, x])\n","    return mha_feature\n","\n","class MultiHeadAttention_LSA(tf.keras.layers.MultiHeadAttention):\n","    \"\"\"Local Multi-head Self Attention block (LSA).\"\"\"\n","    def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","        self.tau = tf.Variable(math.sqrt(float(self._key_dim)), trainable=True)\n","\n","    def _compute_attention(self, query, key, value, attention_mask=None, training=None):\n","        query = tf.multiply(query, 1.0 / self.tau)\n","        attention_scores = tf.einsum(self._dot_product_equation, key, query)\n","        attention_scores = self._masked_softmax(attention_scores, attention_mask)\n","        attention_scores_dropout = self._dropout_layer(attention_scores, training=training)\n","        attention_output = tf.einsum(self._combine_equation, attention_scores_dropout, value)\n","        return attention_output, attention_scores\n","\n","def se_block(input_feature, ratio=8, residual=False, apply_to_input=True):\n","    \"\"\"Squeeze-and-Excitation (SE) block.\"\"\"\n","    channel_axis = 1 if tf.keras.backend.image_data_format() == \"channels_first\" else -1\n","    channel = input_feature.shape[channel_axis]\n","    se_feature = GlobalAveragePooling2D()(input_feature)\n","    se_feature = Reshape((1, 1, channel))(se_feature)\n","    if ratio != 0:\n","        se_feature = Dense(channel // ratio, activation='relu',\n","                           kernel_initializer='he_normal', use_bias=True, bias_initializer='zeros')(se_feature)\n","    se_feature = Dense(channel, activation='sigmoid',\n","                       kernel_initializer='he_normal', use_bias=True, bias_initializer='zeros')(se_feature)\n","    if tf.keras.backend.image_data_format() == 'channels_first':\n","        se_feature = Permute((3, 1, 2))(se_feature)\n","    if apply_to_input:\n","        se_feature = multiply([input_feature, se_feature])\n","    if residual:\n","        se_feature = Add()([se_feature, input_feature])\n","    return se_feature\n","\n","def cbam_block(input_feature, ratio=8, residual=False):\n","    \"\"\"Convolutional Block Attention Module (CBAM) block.\"\"\"\n","    cbam_feature = channel_attention(input_feature, ratio)\n","    cbam_feature = spatial_attention(cbam_feature)\n","    if residual:\n","        cbam_feature = Add()([input_feature, cbam_feature])\n","    return cbam_feature\n","\n","def channel_attention(input_feature, ratio=8):\n","    channel_axis = 1 if tf.keras.backend.image_data_format() == \"channels_first\" else -1\n","    channel = input_feature.shape[channel_axis]\n","    shared_layer_one = Dense(channel // ratio, activation='relu',\n","                             kernel_initializer='he_normal', use_bias=True, bias_initializer='zeros')\n","    shared_layer_two = Dense(channel, kernel_initializer='he_normal',\n","                             use_bias=True, bias_initializer='zeros')\n","\n","    avg_pool = GlobalAveragePooling2D()(input_feature)\n","    avg_pool = Reshape((1, 1, channel))(avg_pool)\n","    avg_pool = shared_layer_one(avg_pool)\n","    avg_pool = shared_layer_two(avg_pool)\n","\n","    max_pool = GlobalMaxPooling2D()(input_feature)\n","    max_pool = Reshape((1, 1, channel))(max_pool)\n","    max_pool = shared_layer_one(max_pool)\n","    max_pool = shared_layer_two(max_pool)\n","\n","    cbam_feature = Add()([avg_pool, max_pool])\n","    cbam_feature = Activation('sigmoid')(cbam_feature)\n","\n","    if tf.keras.backend.image_data_format() == \"channels_first\":\n","        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n","\n","    return multiply([input_feature, cbam_feature])\n","\n","def spatial_attention(input_feature):\n","    kernel_size = 7\n","    if tf.keras.backend.image_data_format() == \"channels_first\":\n","        cbam_feature = Permute((2, 3, 1))(input_feature)\n","    else:\n","        cbam_feature = input_feature\n","    avg_pool = Lambda(lambda x: tf.reduce_mean(x, axis=3, keepdims=True))(cbam_feature)\n","    max_pool = Lambda(lambda x: tf.reduce_max(x, axis=3, keepdims=True))(cbam_feature)\n","    concat = Concatenate(axis=3)([avg_pool, max_pool])\n","    cbam_feature = Conv2D(filters=1, kernel_size=kernel_size, strides=1, padding='same',\n","                          activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(concat)\n","    if tf.keras.backend.image_data_format() == \"channels_first\":\n","        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n","    return multiply([input_feature, cbam_feature])\n","\n","\n","#########################\n","# Original Data Loading & Preprocessing\n","#########################\n","data_path = '/kaggle/input/dataset123321/SEED-VIG_processed (1).csv'\n","df = pd.read_csv(data_path)\n","\n","print(\"Dataset Shape:\", df.shape)\n","print(\"\\nFirst 5 rows:\")\n","print(df.head())\n","print(\"\\nDataset Info:\")\n","print(df.info())\n","print(\"\\nSummary Statistics:\")\n","print(df.describe())\n","print(\"\\nMissing values per column:\")\n","print(df.isnull().sum())\n","print(\"\\nUnique subjects (subindex):\")\n","print(df['subindex'].unique())\n","print(\"\\nClass distribution (substate):\")\n","print(df['substate'].value_counts())\n","\n","# Prepare raw EEG data: features and labels\n","X = df.drop(columns=['subindex', 'substate']).values\n","y = df['substate'].values\n","X = X.reshape(X.shape[0], 17, 384)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n","\n","#########################\n","# Continuous Wavelet Transform Preprocessing\n","#########################\n","def apply_cwt(X, scales, wavelet):\n","    n_samples, n_channels, n_timepoints = X.shape\n","    transformed = []\n","    for i in range(n_samples):\n","        sample = X[i]\n","        channel_cwt = []\n","        for ch in range(n_channels):\n","            coeffs, _ = pywt.cwt(sample[ch], scales, wavelet)\n","            channel_cwt.append(coeffs)\n","        sample_cwt = np.stack(channel_cwt, axis=-1)\n","        transformed.append(sample_cwt)\n","    return np.array(transformed)\n","\n","scales = np.arange(1, 31)  # 30 scales\n","wavelet = 'morl'\n","X_train_cwt = apply_cwt(X_train, scales, wavelet)\n","X_test_cwt  = apply_cwt(X_test, scales, wavelet)\n","print(\"Transformed training data shape:\", X_train_cwt.shape)  # Expected: (n_samples, 30, 384, 17)\n","print(\"Transformed test data shape:\", X_test_cwt.shape)\n","\n","#########################\n","# Adaptive Feature Fusion Module (previous implementation)\n","#########################\n","def adaptive_feature_fusion_module_2d(inputs, filters):\n","    branch1 = layers.Conv2D(filters, kernel_size=(3, 3), padding='same', activation='relu',\n","                              kernel_regularizer=regularizers.l2(0.001))(inputs)\n","    branch1 = layers.BatchNormalization()(branch1)\n","    branch1 = layers.SpatialDropout2D(0.3)(branch1)\n","\n","    branch2 = layers.Conv2D(filters, kernel_size=(5, 5), padding='same', activation='relu',\n","                              kernel_regularizer=regularizers.l2(0.001))(inputs)\n","    branch2 = layers.BatchNormalization()(branch2)\n","    branch2 = layers.SpatialDropout2D(0.3)(branch2)\n","\n","    concat = layers.Concatenate()([branch1, branch2])\n","    fused = layers.Conv2D(filters, kernel_size=(1, 1), padding='same', activation='relu',\n","                          kernel_regularizer=regularizers.l2(0.001))(concat)\n","    fused = layers.BatchNormalization()(fused)\n","    out = layers.Add()([inputs, fused])\n","    return out\n","\n","#########################\n","# Build the Model with Advanced Attention Blocks\n","#########################\n","def build_model_advanced(input_shape, attention_type='cbam'):\n","    \"\"\"\n","    Build a CNN model that uses advanced attention modules.\n","\n","    Parameters:\n","      - input_shape: shape of the input data (e.g., (30, 384, 17))\n","      - attention_type: one of 'cbam', 'se', 'mha', 'mhla'\n","    \"\"\"\n","    inputs = Input(shape=input_shape)\n","    x = layers.GaussianNoise(0.05)(inputs)\n","\n","    # Initial convolutional block\n","    x = layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same',\n","                      kernel_regularizer=regularizers.l2(0.001))(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.SpatialDropout2D(0.3)(x)\n","    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n","\n","    # Apply advanced attention block\n","    x = attention_block(x, attention_model=attention_type, ratio=8, residual=True, apply_to_input=True)\n","\n","    # Adaptive Feature Fusion\n","    x_aff = adaptive_feature_fusion_module_2d(x, 64)\n","    x = layers.Add()([x, x_aff])\n","\n","    # Additional convolutional block\n","    x = layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same',\n","                      kernel_regularizer=regularizers.l2(0.001))(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.SpatialDropout2D(0.3)(x)\n","    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n","\n","    # Optionally, add another advanced attention block here\n","    x = attention_block(x, attention_model=attention_type, ratio=8, residual=True, apply_to_input=True)\n","\n","    x = layers.GlobalAveragePooling2D()(x)\n","    x = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n","    x = layers.Dropout(0.7)(x)\n","    outputs = layers.Dense(1, activation='sigmoid')(x)\n","\n","    model = models.Model(inputs=inputs, outputs=outputs)\n","    model.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# Build and summarize the model with advanced attention (using 'cbam' by default)\n","model_advanced = build_model_advanced((30, 384, 17), attention_type='cbam')\n","model_advanced.summary()\n","\n","#########################\n","# Train the Model\n","#########################\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n","history = model_advanced.fit(X_train_cwt, y_train, epochs=100, batch_size=32,\n","                             validation_data=(X_test_cwt, y_test),\n","                             callbacks=[reduce_lr])\n","\n","#########################\n","# Evaluate the Model\n","#########################\n","y_pred = (model_advanced.predict(X_test_cwt) > 0.5).astype(\"int32\")\n","test_accuracy = accuracy_score(y_test, y_pred)\n","\n","print(\"\\nTrain Accuracy:\", history.history['accuracy'][-1])\n","print(\"\\nValidation Accuracy:\", history.history['val_accuracy'][-1])\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_test, y_pred))\n","print(\"\\nConfusion Matrix:\")\n","print(confusion_matrix(y_test, y_pred))\n","print(\"\\nTest Accuracy:\", test_accuracy)\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T10:39:00.273597Z","iopub.execute_input":"2025-03-11T10:39:00.273870Z","iopub.status.idle":"2025-03-11T10:55:53.512535Z","shell.execute_reply.started":"2025-03-11T10:39:00.273847Z","shell.execute_reply":"2025-03-11T10:55:53.511801Z"},"id":"7hztjm-Yxx3M","outputId":"6641346f-64ab-4ae3-a8b4-ccd98c8de603"},"outputs":[{"name":"stdout","text":"Dataset Shape: (4566, 6530)\n\nFirst 5 rows:\n   EEG_channel_1_t1  EEG_channel_1_t2  EEG_channel_1_t3  EEG_channel_1_t4  \\\n0         -3.457432        -15.610134        -28.209033        -16.500817   \n1         12.856846          7.200323          4.795857         13.225275   \n2         13.143232          3.307855          8.480391          7.013710   \n3         30.523582         28.615215         41.685072         28.333728   \n4         -8.910801        -10.594044        -30.384980        -10.884113   \n\n   EEG_channel_1_t5  EEG_channel_1_t6  EEG_channel_1_t7  EEG_channel_1_t8  \\\n0        -16.546740        -24.126600        -24.409480         -5.469685   \n1          3.833067         15.926209         11.693700          9.498457   \n2          2.753549         -6.774113          7.940243          2.431553   \n3         25.406661         16.704956         18.192949         29.348514   \n4         -2.765033         -6.931607         -2.220146         -5.399940   \n\n   EEG_channel_1_t9  EEG_channel_1_t10  ...  EEG_channel_17_t377  \\\n0          1.154248         -23.348832  ...           -12.903784   \n1          0.681183          -4.510141  ...            -7.658388   \n2         -8.707217          14.751186  ...             4.581718   \n3         32.597912          47.208990  ...            11.325625   \n4         10.424233           6.586768  ...            10.188376   \n\n   EEG_channel_17_t378  EEG_channel_17_t379  EEG_channel_17_t380  \\\n0            11.738216            11.750432           -11.884572   \n1            -5.435635             4.390848            -6.110258   \n2           -16.451593           -18.184260            -7.998739   \n3            -1.553963             9.147236             4.571954   \n4             4.403909             7.867480             3.094053   \n\n   EEG_channel_17_t381  EEG_channel_17_t382  EEG_channel_17_t383  \\\n0            11.557981             3.670015             1.022389   \n1            -7.350371            -9.266211            -3.463253   \n2             3.442156             5.916290            11.327448   \n3            -5.976720             9.201917             3.264484   \n4            -8.918453            -8.258792            -3.794030   \n\n   EEG_channel_17_t384  subindex  substate  \n0             6.678800       1.0       0.0  \n1             0.988364       1.0       0.0  \n2             7.235500       1.0       0.0  \n3             9.126078       1.0       0.0  \n4            -6.771443       1.0       0.0  \n\n[5 rows x 6530 columns]\n\nDataset Info:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4566 entries, 0 to 4565\nColumns: 6530 entries, EEG_channel_1_t1 to substate\ndtypes: float64(6530)\nmemory usage: 227.5 MB\nNone\n\nSummary Statistics:\n       EEG_channel_1_t1  EEG_channel_1_t2  EEG_channel_1_t3  EEG_channel_1_t4  \\\ncount       4566.000000       4566.000000       4566.000000       4566.000000   \nmean           0.268995          0.178587          0.251050          0.379959   \nstd           14.239495         14.479210         13.946723         13.838889   \nmin         -182.928571       -218.523174       -165.234172       -165.299720   \n25%           -6.416277         -6.261191         -6.501841         -6.395290   \n50%            0.190094          0.116685          0.329852          0.148091   \n75%            6.694287          6.689481          6.888517          6.774481   \nmax          198.446845        113.263287        146.589238        113.178073   \n\n       EEG_channel_1_t5  EEG_channel_1_t6  EEG_channel_1_t7  EEG_channel_1_t8  \\\ncount       4566.000000       4566.000000       4566.000000       4566.000000   \nmean           0.342326          0.181720          0.277041         -0.021449   \nstd           14.548821         14.793686         13.952729         14.223486   \nmin         -238.433889       -210.974404       -179.778277       -193.189071   \n25%           -6.496245         -6.317452         -6.390703         -6.511990   \n50%            0.227434          0.035486          0.031584         -0.149774   \n75%            6.757224          6.853751          6.789876          6.476947   \nmax          197.340390        119.037552        115.463636        126.249387   \n\n       EEG_channel_1_t9  EEG_channel_1_t10  ...  EEG_channel_17_t377  \\\ncount       4566.000000        4566.000000  ...          4566.000000   \nmean          -0.100263           0.134714  ...            -0.005756   \nstd           14.603237          14.633034  ...            12.103472   \nmin         -216.848994        -185.571488  ...          -137.778304   \n25%           -6.604605          -6.567120  ...            -4.775599   \n50%           -0.230334          -0.078498  ...             0.094540   \n75%            6.521189           6.612657  ...             5.019160   \nmax          133.103531         244.539111  ...           254.865644   \n\n       EEG_channel_17_t378  EEG_channel_17_t379  EEG_channel_17_t380  \\\ncount          4566.000000          4566.000000          4566.000000   \nmean              0.035030             0.052978             0.012658   \nstd              14.347317            12.028139            11.996047   \nmin            -132.337392          -131.555968          -136.234839   \n25%              -4.903859            -4.956307            -4.978891   \n50%               0.177784             0.274492             0.293792   \n75%               4.877808             5.049747             4.979423   \nmax             541.175324           245.467248           243.928531   \n\n       EEG_channel_17_t381  EEG_channel_17_t382  EEG_channel_17_t383  \\\ncount          4566.000000          4566.000000          4566.000000   \nmean              0.046098             0.049606             0.144644   \nstd              11.887679            11.939745            11.867162   \nmin            -133.674902          -135.650434          -139.667369   \n25%              -4.937081            -4.901380            -4.804837   \n50%               0.197702             0.181499             0.297601   \n75%               4.994321             5.081251             5.301908   \nmax             241.071383           233.626849           203.164746   \n\n       EEG_channel_17_t384     subindex     substate  \ncount          4566.000000  4566.000000  4566.000000  \nmean              0.075223     6.963206     0.500000  \nstd              11.991860     3.256061     0.500055  \nmin            -140.754090     1.000000     0.000000  \n25%              -4.818638     4.000000     0.000000  \n50%               0.261025     7.000000     0.500000  \n75%               5.025526    10.000000     1.000000  \nmax             224.630755    12.000000     1.000000  \n\n[8 rows x 6530 columns]\n\nMissing values per column:\nEEG_channel_1_t1       0\nEEG_channel_1_t2       0\nEEG_channel_1_t3       0\nEEG_channel_1_t4       0\nEEG_channel_1_t5       0\n                      ..\nEEG_channel_17_t382    0\nEEG_channel_17_t383    0\nEEG_channel_17_t384    0\nsubindex               0\nsubstate               0\nLength: 6530, dtype: int64\n\nUnique subjects (subindex):\n[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.]\n\nClass distribution (substate):\nsubstate\n0.0    2283\n1.0    2283\nName: count, dtype: int64\nTransformed training data shape: (3652, 30, 384, 17)\nTransformed test data shape: (914, 30, 384, 17)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m384\u001b[0m, \u001b[38;5;34m17\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ gaussian_noise            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m384\u001b[0m, \u001b[38;5;34m17\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mGaussianNoise\u001b[0m)           │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m384\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m9,856\u001b[0m │ gaussian_noise[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m384\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │            \u001b[38;5;34m256\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ spatial_dropout2d         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m384\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)        │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ spatial_dropout2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling2d  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_max_pooling2d      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mGlobalMaxPooling2D\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ reshape (\u001b[38;5;33mReshape\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ global_max_pooling2d[\u001b[38;5;34m…\u001b[0m │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │            \u001b[38;5;34m520\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n│                           │                        │                │ reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │            \u001b[38;5;34m576\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n│                           │                        │                │ dense[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add (\u001b[38;5;33mAdd\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n│                           │                        │                │ dense_1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation (\u001b[38;5;33mActivation\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multiply (\u001b[38;5;33mMultiply\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│                           │                        │                │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ lambda (\u001b[38;5;33mLambda\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ lambda_1 (\u001b[38;5;33mLambda\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m2\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n│                           │                        │                │ lambda_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │             \u001b[38;5;34m98\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multiply_1 (\u001b[38;5;33mMultiply\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│                           │                        │                │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_1 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│                           │                        │                │ multiply_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │         \u001b[38;5;34m36,928\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m102,464\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │            \u001b[38;5;34m256\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │            \u001b[38;5;34m256\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ spatial_dropout2d_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)        │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ spatial_dropout2d_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_2… │\n│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)        │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ spatial_dropout2d_1[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ spatial_dropout2d_2[\u001b[38;5;34m0\u001b[0m… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m8,256\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │            \u001b[38;5;34m256\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_2 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n│                           │                        │                │ batch_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_3 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n│                           │                        │                │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │         \u001b[38;5;34m73,856\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │            \u001b[38;5;34m512\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ spatial_dropout2d_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_4… │\n│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)        │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ spatial_dropout2d_3[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling2d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_max_pooling2d_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n│ (\u001b[38;5;33mGlobalMaxPooling2D\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ reshape_3 (\u001b[38;5;33mReshape\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ global_max_pooling2d_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │          \u001b[38;5;34m2,064\u001b[0m │ reshape_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n│                           │                        │                │ reshape_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │          \u001b[38;5;34m2,176\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n│                           │                        │                │ dense_2[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_4 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n│                           │                        │                │ dense_3[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_1 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multiply_2 (\u001b[38;5;33mMultiply\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│                           │                        │                │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ lambda_2 (\u001b[38;5;33mLambda\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m1\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multiply_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ lambda_3 (\u001b[38;5;33mLambda\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m1\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multiply_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m2\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ lambda_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ lambda_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m1\u001b[0m)       │             \u001b[38;5;34m98\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multiply_3 (\u001b[38;5;33mMultiply\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ multiply_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n│                           │                        │                │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_5 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│                           │                        │                │ multiply_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling2d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_4 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m16,512\u001b[0m │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_5 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m129\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ gaussian_noise            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)           │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,856</span> │ gaussian_noise[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ spatial_dropout2d         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)        │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ spatial_dropout2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling2d  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_max_pooling2d      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling2D</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n│                           │                        │                │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n│                           │                        │                │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n│                           │                        │                │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│                           │                        │                │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n│                           │                        │                │ lambda_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multiply_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│                           │                        │                │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│                           │                        │                │ multiply_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">102,464</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ spatial_dropout2d_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)        │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ spatial_dropout2d_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_2… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)        │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ spatial_dropout2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ spatial_dropout2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n│                           │                        │                │ batch_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n│                           │                        │                │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ spatial_dropout2d_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_4… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)        │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ spatial_dropout2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling2d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_max_pooling2d_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling2D</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ reshape_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooling2d_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,064</span> │ reshape_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n│                           │                        │                │ reshape_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,176</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n│                           │                        │                │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n│                           │                        │                │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multiply_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│                           │                        │                │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ lambda_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ lambda_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ lambda_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multiply_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n│                           │                        │                │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│                           │                        │                │ multiply_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling2d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ global_average_poolin… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m255,069\u001b[0m (996.36 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">255,069</span> (996.36 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m254,301\u001b[0m (993.36 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">254,301</span> (993.36 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 277ms/step - accuracy: 0.6873 - loss: 1.0710 - val_accuracy: 0.8315 - val_loss: 0.8239 - learning_rate: 5.0000e-04\nEpoch 2/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 0.8433 - loss: 0.7920 - val_accuracy: 0.7801 - val_loss: 0.8639 - learning_rate: 5.0000e-04\nEpoch 3/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 0.8737 - loss: 0.6962 - val_accuracy: 0.7243 - val_loss: 0.9394 - learning_rate: 5.0000e-04\nEpoch 4/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 0.9047 - loss: 0.6010 - val_accuracy: 0.8731 - val_loss: 0.6232 - learning_rate: 5.0000e-04\nEpoch 5/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 0.9016 - loss: 0.5837 - val_accuracy: 0.8643 - val_loss: 0.6431 - learning_rate: 5.0000e-04\nEpoch 6/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 0.9014 - loss: 0.5311 - val_accuracy: 0.7702 - val_loss: 0.8310 - learning_rate: 5.0000e-04\nEpoch 7/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9106 - loss: 0.5060 - val_accuracy: 0.8917 - val_loss: 0.5207 - learning_rate: 5.0000e-04\nEpoch 8/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9136 - loss: 0.4704 - val_accuracy: 0.8217 - val_loss: 0.6587 - learning_rate: 5.0000e-04\nEpoch 9/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9291 - loss: 0.4204 - val_accuracy: 0.8184 - val_loss: 0.6533 - learning_rate: 5.0000e-04\nEpoch 10/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - accuracy: 0.9221 - loss: 0.4151 - val_accuracy: 0.8392 - val_loss: 0.5747 - learning_rate: 5.0000e-04\nEpoch 11/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - accuracy: 0.9300 - loss: 0.4038 - val_accuracy: 0.8928 - val_loss: 0.4440 - learning_rate: 5.0000e-04\nEpoch 12/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9328 - loss: 0.3740 - val_accuracy: 0.8731 - val_loss: 0.5006 - learning_rate: 5.0000e-04\nEpoch 13/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9337 - loss: 0.3618 - val_accuracy: 0.9037 - val_loss: 0.3979 - learning_rate: 5.0000e-04\nEpoch 14/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9190 - loss: 0.3883 - val_accuracy: 0.9453 - val_loss: 0.3029 - learning_rate: 5.0000e-04\nEpoch 15/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9374 - loss: 0.3438 - val_accuracy: 0.9322 - val_loss: 0.3200 - learning_rate: 5.0000e-04\nEpoch 16/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9322 - loss: 0.3462 - val_accuracy: 0.9267 - val_loss: 0.3287 - learning_rate: 5.0000e-04\nEpoch 17/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9380 - loss: 0.3260 - val_accuracy: 0.9267 - val_loss: 0.3277 - learning_rate: 5.0000e-04\nEpoch 18/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9341 - loss: 0.3050 - val_accuracy: 0.9048 - val_loss: 0.3568 - learning_rate: 5.0000e-04\nEpoch 19/100\n\u001b[1m114/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9402 - loss: 0.2943\nEpoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9401 - loss: 0.2945 - val_accuracy: 0.8906 - val_loss: 0.3874 - learning_rate: 5.0000e-04\nEpoch 20/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9409 - loss: 0.2858 - val_accuracy: 0.8709 - val_loss: 0.4438 - learning_rate: 2.5000e-04\nEpoch 21/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9331 - loss: 0.2875 - val_accuracy: 0.9059 - val_loss: 0.3504 - learning_rate: 2.5000e-04\nEpoch 22/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9396 - loss: 0.2717 - val_accuracy: 0.9026 - val_loss: 0.3675 - learning_rate: 2.5000e-04\nEpoch 23/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9462 - loss: 0.2638 - val_accuracy: 0.9311 - val_loss: 0.2943 - learning_rate: 2.5000e-04\nEpoch 24/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9488 - loss: 0.2528 - val_accuracy: 0.9081 - val_loss: 0.3368 - learning_rate: 2.5000e-04\nEpoch 25/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9464 - loss: 0.2608 - val_accuracy: 0.9333 - val_loss: 0.2712 - learning_rate: 2.5000e-04\nEpoch 26/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9478 - loss: 0.2619 - val_accuracy: 0.8939 - val_loss: 0.3523 - learning_rate: 2.5000e-04\nEpoch 27/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9362 - loss: 0.2809 - val_accuracy: 0.9311 - val_loss: 0.2760 - learning_rate: 2.5000e-04\nEpoch 28/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9513 - loss: 0.2337 - val_accuracy: 0.9223 - val_loss: 0.2929 - learning_rate: 2.5000e-04\nEpoch 29/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9461 - loss: 0.2338 - val_accuracy: 0.9103 - val_loss: 0.3151 - learning_rate: 2.5000e-04\nEpoch 30/100\n\u001b[1m114/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9536 - loss: 0.2248\nEpoch 30: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9535 - loss: 0.2250 - val_accuracy: 0.9201 - val_loss: 0.2835 - learning_rate: 2.5000e-04\nEpoch 31/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9479 - loss: 0.2328 - val_accuracy: 0.8906 - val_loss: 0.3323 - learning_rate: 1.2500e-04\nEpoch 32/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9466 - loss: 0.2310 - val_accuracy: 0.9168 - val_loss: 0.2845 - learning_rate: 1.2500e-04\nEpoch 33/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9526 - loss: 0.2260 - val_accuracy: 0.9344 - val_loss: 0.2445 - learning_rate: 1.2500e-04\nEpoch 34/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9486 - loss: 0.2321 - val_accuracy: 0.9179 - val_loss: 0.2841 - learning_rate: 1.2500e-04\nEpoch 35/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9507 - loss: 0.2376 - val_accuracy: 0.8972 - val_loss: 0.3347 - learning_rate: 1.2500e-04\nEpoch 36/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9640 - loss: 0.2026 - val_accuracy: 0.9125 - val_loss: 0.2911 - learning_rate: 1.2500e-04\nEpoch 37/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9496 - loss: 0.2277 - val_accuracy: 0.9267 - val_loss: 0.2573 - learning_rate: 1.2500e-04\nEpoch 38/100\n\u001b[1m114/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9551 - loss: 0.2191\nEpoch 38: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9550 - loss: 0.2191 - val_accuracy: 0.9201 - val_loss: 0.2647 - learning_rate: 1.2500e-04\nEpoch 39/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9542 - loss: 0.2209 - val_accuracy: 0.9212 - val_loss: 0.2590 - learning_rate: 6.2500e-05\nEpoch 40/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9531 - loss: 0.2046 - val_accuracy: 0.9300 - val_loss: 0.2469 - learning_rate: 6.2500e-05\nEpoch 41/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9521 - loss: 0.2166 - val_accuracy: 0.9409 - val_loss: 0.2254 - learning_rate: 6.2500e-05\nEpoch 42/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9585 - loss: 0.1961 - val_accuracy: 0.9365 - val_loss: 0.2307 - learning_rate: 6.2500e-05\nEpoch 43/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9557 - loss: 0.1985 - val_accuracy: 0.9464 - val_loss: 0.2166 - learning_rate: 6.2500e-05\nEpoch 44/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9545 - loss: 0.2016 - val_accuracy: 0.9376 - val_loss: 0.2273 - learning_rate: 6.2500e-05\nEpoch 45/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9568 - loss: 0.1933 - val_accuracy: 0.9354 - val_loss: 0.2318 - learning_rate: 6.2500e-05\nEpoch 46/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9600 - loss: 0.1852 - val_accuracy: 0.9376 - val_loss: 0.2324 - learning_rate: 6.2500e-05\nEpoch 47/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9625 - loss: 0.1891 - val_accuracy: 0.9311 - val_loss: 0.2512 - learning_rate: 6.2500e-05\nEpoch 48/100\n\u001b[1m114/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9596 - loss: 0.1869\nEpoch 48: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9596 - loss: 0.1871 - val_accuracy: 0.9409 - val_loss: 0.2229 - learning_rate: 6.2500e-05\nEpoch 49/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9645 - loss: 0.1805 - val_accuracy: 0.9344 - val_loss: 0.2420 - learning_rate: 3.1250e-05\nEpoch 50/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9554 - loss: 0.1950 - val_accuracy: 0.9311 - val_loss: 0.2456 - learning_rate: 3.1250e-05\nEpoch 51/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9659 - loss: 0.1796 - val_accuracy: 0.9278 - val_loss: 0.2522 - learning_rate: 3.1250e-05\nEpoch 52/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9541 - loss: 0.2008 - val_accuracy: 0.9398 - val_loss: 0.2269 - learning_rate: 3.1250e-05\nEpoch 53/100\n\u001b[1m114/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9602 - loss: 0.1819\nEpoch 53: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9602 - loss: 0.1819 - val_accuracy: 0.9289 - val_loss: 0.2560 - learning_rate: 3.1250e-05\nEpoch 54/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9621 - loss: 0.1909 - val_accuracy: 0.9278 - val_loss: 0.2565 - learning_rate: 1.5625e-05\nEpoch 55/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9632 - loss: 0.1843 - val_accuracy: 0.9311 - val_loss: 0.2437 - learning_rate: 1.5625e-05\nEpoch 56/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9613 - loss: 0.1860 - val_accuracy: 0.9365 - val_loss: 0.2340 - learning_rate: 1.5625e-05\nEpoch 57/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9603 - loss: 0.1822 - val_accuracy: 0.9333 - val_loss: 0.2379 - learning_rate: 1.5625e-05\nEpoch 58/100\n\u001b[1m114/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9617 - loss: 0.1799\nEpoch 58: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9617 - loss: 0.1799 - val_accuracy: 0.9376 - val_loss: 0.2278 - learning_rate: 1.5625e-05\nEpoch 59/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9550 - loss: 0.1974 - val_accuracy: 0.9431 - val_loss: 0.2182 - learning_rate: 7.8125e-06\nEpoch 60/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9656 - loss: 0.1797 - val_accuracy: 0.9289 - val_loss: 0.2479 - learning_rate: 7.8125e-06\nEpoch 61/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9569 - loss: 0.1868 - val_accuracy: 0.9344 - val_loss: 0.2414 - learning_rate: 7.8125e-06\nEpoch 62/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9585 - loss: 0.1918 - val_accuracy: 0.9420 - val_loss: 0.2147 - learning_rate: 7.8125e-06\nEpoch 63/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9634 - loss: 0.1772 - val_accuracy: 0.9333 - val_loss: 0.2439 - learning_rate: 7.8125e-06\nEpoch 64/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9602 - loss: 0.1881 - val_accuracy: 0.9354 - val_loss: 0.2385 - learning_rate: 7.8125e-06\nEpoch 65/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9614 - loss: 0.1864 - val_accuracy: 0.9420 - val_loss: 0.2171 - learning_rate: 7.8125e-06\nEpoch 66/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9633 - loss: 0.1755 - val_accuracy: 0.9344 - val_loss: 0.2384 - learning_rate: 7.8125e-06\nEpoch 67/100\n\u001b[1m114/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9652 - loss: 0.1690\nEpoch 67: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9651 - loss: 0.1691 - val_accuracy: 0.9354 - val_loss: 0.2313 - learning_rate: 7.8125e-06\nEpoch 68/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9621 - loss: 0.1798 - val_accuracy: 0.9365 - val_loss: 0.2319 - learning_rate: 3.9063e-06\nEpoch 69/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9600 - loss: 0.1896 - val_accuracy: 0.9344 - val_loss: 0.2405 - learning_rate: 3.9063e-06\nEpoch 70/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9581 - loss: 0.1919 - val_accuracy: 0.9333 - val_loss: 0.2374 - learning_rate: 3.9063e-06\nEpoch 71/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9681 - loss: 0.1738 - val_accuracy: 0.9278 - val_loss: 0.2512 - learning_rate: 3.9063e-06\nEpoch 72/100\n\u001b[1m114/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9658 - loss: 0.1766\nEpoch 72: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9657 - loss: 0.1767 - val_accuracy: 0.9376 - val_loss: 0.2236 - learning_rate: 3.9063e-06\nEpoch 73/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9583 - loss: 0.1798 - val_accuracy: 0.9376 - val_loss: 0.2267 - learning_rate: 1.9531e-06\nEpoch 74/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9629 - loss: 0.1812 - val_accuracy: 0.9376 - val_loss: 0.2269 - learning_rate: 1.9531e-06\nEpoch 75/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9680 - loss: 0.1614 - val_accuracy: 0.9311 - val_loss: 0.2448 - learning_rate: 1.9531e-06\nEpoch 76/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9579 - loss: 0.1910 - val_accuracy: 0.9333 - val_loss: 0.2379 - learning_rate: 1.9531e-06\nEpoch 77/100\n\u001b[1m114/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9593 - loss: 0.1872\nEpoch 77: ReduceLROnPlateau reducing learning rate to 1e-06.\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9594 - loss: 0.1872 - val_accuracy: 0.9387 - val_loss: 0.2222 - learning_rate: 1.9531e-06\nEpoch 78/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9647 - loss: 0.1770 - val_accuracy: 0.9453 - val_loss: 0.2151 - learning_rate: 1.0000e-06\nEpoch 79/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9593 - loss: 0.1780 - val_accuracy: 0.9322 - val_loss: 0.2341 - learning_rate: 1.0000e-06\nEpoch 80/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9660 - loss: 0.1728 - val_accuracy: 0.9398 - val_loss: 0.2222 - learning_rate: 1.0000e-06\nEpoch 81/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9631 - loss: 0.1771 - val_accuracy: 0.9431 - val_loss: 0.2181 - learning_rate: 1.0000e-06\nEpoch 82/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9643 - loss: 0.1682 - val_accuracy: 0.9311 - val_loss: 0.2394 - learning_rate: 1.0000e-06\nEpoch 83/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9635 - loss: 0.1689 - val_accuracy: 0.9278 - val_loss: 0.2500 - learning_rate: 1.0000e-06\nEpoch 84/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9595 - loss: 0.1812 - val_accuracy: 0.9333 - val_loss: 0.2353 - learning_rate: 1.0000e-06\nEpoch 85/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9651 - loss: 0.1729 - val_accuracy: 0.9278 - val_loss: 0.2468 - learning_rate: 1.0000e-06\nEpoch 86/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9641 - loss: 0.1765 - val_accuracy: 0.9333 - val_loss: 0.2390 - learning_rate: 1.0000e-06\nEpoch 87/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9650 - loss: 0.1768 - val_accuracy: 0.9376 - val_loss: 0.2282 - learning_rate: 1.0000e-06\nEpoch 88/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9647 - loss: 0.1827 - val_accuracy: 0.9376 - val_loss: 0.2240 - learning_rate: 1.0000e-06\nEpoch 89/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9583 - loss: 0.1858 - val_accuracy: 0.9333 - val_loss: 0.2404 - learning_rate: 1.0000e-06\nEpoch 90/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9554 - loss: 0.1906 - val_accuracy: 0.9376 - val_loss: 0.2275 - learning_rate: 1.0000e-06\nEpoch 91/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9603 - loss: 0.1759 - val_accuracy: 0.9376 - val_loss: 0.2256 - learning_rate: 1.0000e-06\nEpoch 92/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9638 - loss: 0.1751 - val_accuracy: 0.9431 - val_loss: 0.2166 - learning_rate: 1.0000e-06\nEpoch 93/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9654 - loss: 0.1637 - val_accuracy: 0.9409 - val_loss: 0.2199 - learning_rate: 1.0000e-06\nEpoch 94/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9650 - loss: 0.1658 - val_accuracy: 0.9398 - val_loss: 0.2233 - learning_rate: 1.0000e-06\nEpoch 95/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9553 - loss: 0.1866 - val_accuracy: 0.9442 - val_loss: 0.2164 - learning_rate: 1.0000e-06\nEpoch 96/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9570 - loss: 0.1850 - val_accuracy: 0.9464 - val_loss: 0.2124 - learning_rate: 1.0000e-06\nEpoch 97/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9574 - loss: 0.1813 - val_accuracy: 0.9354 - val_loss: 0.2322 - learning_rate: 1.0000e-06\nEpoch 98/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9719 - loss: 0.1599 - val_accuracy: 0.9376 - val_loss: 0.2273 - learning_rate: 1.0000e-06\nEpoch 99/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.9647 - loss: 0.1678 - val_accuracy: 0.9333 - val_loss: 0.2350 - learning_rate: 1.0000e-06\nEpoch 100/100\n\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - accuracy: 0.9590 - loss: 0.1786 - val_accuracy: 0.9420 - val_loss: 0.2174 - learning_rate: 1.0000e-06\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 102ms/step\n\nTrain Accuracy: 0.9592004418373108\n\nValidation Accuracy: 0.942013144493103\n\nClassification Report:\n              precision    recall  f1-score   support\n\n         0.0       0.90      0.99      0.94       457\n         1.0       0.99      0.89      0.94       457\n\n    accuracy                           0.94       914\n   macro avg       0.95      0.94      0.94       914\nweighted avg       0.95      0.94      0.94       914\n\n\nConfusion Matrix:\n[[452   5]\n [ 48 409]]\n\nTest Accuracy: 0.9420131291028446\n","output_type":"stream"}],"execution_count":null}]}